{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extractive Text Summarization\n",
    "    - It is the traditional method developed first. The main objective is to identify the significant sentences of the text and add them to the summary. You need to note that the summary obtained contains exact sentences from the original text.\n",
    "- Abstractive Text Summarization\n",
    "    - The approach is to identify the important sections, interpret the context and reproduce in a new way. This ensures that the core information is conveyed through shortest text possible. Note that here, the sentences in summary are generated, not just extracted from original text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textrank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Textrank is a graph-based ranking algorithm like Google’s PageRank algorithm which has been successfully implemented in citation analysis. We use text rank often for keyword extraction, automated text summarization and phrase ranking. Basically, in the text rank algorithm, we measure the relationship between two or more words.\n",
    "- PageRank (PR) is an algorithm used by Google Search to rank websites in their search engine results. PageRank was named after Larry Page, one of the founders of Google.\n",
    "- The PageRank algorithm outputs a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page. PageRank can be calculated for collections of documents of any size.\n",
    "- Similar to page Rank, text rank is also a graph-based ranking algorithm. Instead of webpage links, TextRank algorithms work on words and sentences(word embedding or sentence embedding). And Instead of counting incoming links here, the similarity between sentences is used.\n",
    "- Algorithm:\n",
    "    1. Take a document with n sentence.\n",
    "    2. compute embedding of each sentence using Tf-IDF, Bert, etc.\n",
    "    3. calculate the similarity between each sentence, which will be nothing but a matrix M which you see above in implementation.\n",
    "    4. Normalise the cosine Matrix M, so that each row sum equals one.\n",
    "    5. Then use page rank algorithms to compute the rank of each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How does LexRank work?\n",
    "    - A sentence which is similar to many other sentences of the text has a high probability of being important. The approach of LexRank is that a particular sentence is recommended by other similar sentences and hence is ranked higher.\n",
    "    - Higher the rank, higher is the priority of being included in the summarized text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luhn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Luhn Summarization algorithm’s approach is based on TF-IDF (Term Frequency-Inverse Document Frequency). It is useful when very low frequent words as well as highly frequent words(stopwords) are both not significant.\n",
    "- Based on this, sentence scoring is carried out and the high ranking sentences make it to the summary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dee59364fa1eaadf1bea23478f28c2088062cd334c11dc706b3988cb0ea7873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
